{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley Values with MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our RNA Sequencing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "DATADIR = '/fdata/ohsu_data/'\n",
    "\n",
    "X_rna_seq = pickle.load(open(DATADIR + 'X_rna_seq.p','rb'))\n",
    "X_rna_seq = X_rna_seq.loc[:,~X_rna_seq.columns.duplicated()]\n",
    "X_drug_labels = pickle.load(open(DATADIR + 'X_drug_labels.p','rb'))\n",
    "final_frame = pickle.load(open(DATADIR + 'final_frame.p','rb'))\n",
    "\n",
    "X = pd.concat([X_drug_labels,X_rna_seq],axis=1)\n",
    "y = final_frame.IC50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MERGE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "merge_df = pd.read_csv(\"merge_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = merge_df.transpose()\n",
    "new_header = merge_df.iloc[0] #grab the first row for the header\n",
    "merge_df = merge_df[1:] #take the data less the header row\n",
    "merge_df.columns = new_header #set the header row as the df header\n",
    "merge_df = merge_df.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some genes are present only in the MERGE dataset, while some are only present in the RNA-seq data.  Here we limit ourselves to only considering the genes present in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overlapping_genes = list(set(merge_df.columns).intersection(rna_seq.columns))\n",
    "merge_df = merge_df[overlapping_genes]\n",
    "rna_seq = pd.concat([rna_seq[['patient_id']], rna_seq[overlapping_genes]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our Drug Response Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drug response data (our $y$'s) are _very_ bimodal.  As such, here we rescale it to make model prediction less insane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "y_train = sc.fit_transform(y_train.values.reshape(-1,1))\n",
    "y_test = sc.transform(y_test.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "y_train = y_train.reshape(y_train.shape[0])\n",
    "y_test = y_test.reshape(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate the set of model inputs that we will use (i.e., our $x$).  For each drug response row in $y$, we grab the RNA-seq data for that patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MultiDrugMLP(nn.Module):\n",
    "    def __init__(self, ngenes, ndrugs, dropout):\n",
    "        super(MultiDrugMLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(ngenes, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(500, 250),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(250, ndrugs)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "mlp = MultiDrugMLP(\n",
    "    ngenes = X_train.shape[1],\n",
    "    ndrugs = 1,\n",
    "    dropout = 0.5\n",
    ").cuda()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(mlp.parameters(),\n",
    "                       lr=1e-5, weight_decay=5e-3)\n",
    "criterion = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import datetime\n",
    "import time\n",
    "from IPython.core.debugger import set_trace\n",
    "from models.models import GCN\n",
    "\n",
    "def train(model, num_epochs, X_train, X_test, y_train, y_test, batch_size):\n",
    "     \n",
    "    X_test = torch.FloatTensor(X_test).cuda()\n",
    "    y_test = torch.FloatTensor(y_test).cuda()\n",
    "    \n",
    "    print(\"Beginning model training at {}\".format(datetime.datetime.now()))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        for i in range(0, X_train.shape[0], batch_size):\n",
    "            X_batch = torch.FloatTensor(X_train[i:i+batch_size]).cuda()\n",
    "            y_batch = torch.FloatTensor(y_train[i:i+batch_size]).cuda()\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Convert batch_size x 1 tensor into 1d tensor of length batch_size\n",
    "            output = model(X_batch)\n",
    "            \n",
    "            loss_train = criterion(output, y_batch) + 0.001*(torch.norm(model.layers[0].weight, p=1) + torch.norm(model.layers[3].weight, p=1) + torch.norm(model.layers[6].weight, p=1))\n",
    "            \n",
    "            #print(\"Epoch {} batch {}/{} train loss {}\".format(epoch, i+batch_size, x_train.shape[0], loss_train))\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        model.eval()\n",
    "        output = model(X_test).squeeze(1)\n",
    "        loss_test = criterion(output, y_test)\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        \n",
    "        print(\"Epoch {} completed in {} secs with test loss {:.4f}\".format(epoch, epoch_time, loss_test.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning model training at 2019-10-15 15:37:48.415739\n",
      "Epoch 0 completed in 4.801731586456299 secs with test loss 1.0273\n",
      "Epoch 1 completed in 4.43738317489624 secs with test loss 1.0271\n",
      "Epoch 2 completed in 4.649473428726196 secs with test loss 1.0264\n",
      "Epoch 3 completed in 4.282020330429077 secs with test loss 1.0267\n",
      "Epoch 4 completed in 4.561908960342407 secs with test loss 1.0269\n",
      "Epoch 5 completed in 4.641335964202881 secs with test loss 1.0268\n",
      "Epoch 6 completed in 4.37453818321228 secs with test loss 1.0268\n",
      "Epoch 7 completed in 4.597288131713867 secs with test loss 1.0268\n",
      "Epoch 8 completed in 4.561112642288208 secs with test loss 1.0268\n",
      "Epoch 9 completed in 4.685428142547607 secs with test loss 1.0268\n",
      "Epoch 10 completed in 4.867961406707764 secs with test loss 1.0268\n",
      "Epoch 11 completed in 4.804675340652466 secs with test loss 1.0268\n",
      "Epoch 12 completed in 4.784103631973267 secs with test loss 1.0268\n",
      "Epoch 13 completed in 4.9442548751831055 secs with test loss 1.0268\n",
      "Epoch 14 completed in 4.847661972045898 secs with test loss 1.0268\n",
      "Epoch 15 completed in 4.640232563018799 secs with test loss 1.0268\n",
      "Epoch 16 completed in 4.751985788345337 secs with test loss 1.0268\n",
      "Epoch 17 completed in 4.560386896133423 secs with test loss 1.0268\n",
      "Epoch 18 completed in 4.793169021606445 secs with test loss 1.0268\n",
      "Epoch 19 completed in 4.686581134796143 secs with test loss 1.0268\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-0b10f89d3c17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-1c13d2ed694f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, num_epochs, X_train, X_test, y_train, y_test, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(mlp, num_epochs = 1000, X_train = X_train, X_test = X_test, y_train = y_train, y_test = y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}